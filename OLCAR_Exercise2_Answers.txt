
Exercise 2a: Mountain Car
===========================

---------------------------
Question 1: Build a probabilistic model of the system. What is the stochastic element in the modeling process and what is its significance? What modeling parameters have the most effect on the quality of the solution?

The probabilistic elemet comes from the fact that there are several modeling iterations (Parameters.modeling_iter). For each action and for each state, the value of the corresponding matrices P_s_sp_a and R_s_s_a are updated multiple times.



---------------------------
Question 2: Implement the Generalized Policy Improvement algorithm introduced in Section 2.8.3. Use appropriate terminal conditions for Policy Evaluation and Policy Improvement processes and implement the Policy Iteration and the Value Iteration algorithms. Think about what the optimal solution to this task should be for the Mountain Car system. Was the learning algorithm able to find this solution? If not, why
do you think that is the case?



---------------------------
Question 3: Now build a deterministic discrete state=action space model of the system (i.e. set the number of modeling iterations to 1). Is it possible to find a policy which reaches the goal? What problems are faced when discretizing the system in this way?



Exercise 2b: Cliff World
===========================

---------------------------
Question 4: First implement the Monte Carlo algorithm. Test the algorithm using different values of epsilon. What impact does epsilon have on the solution? Can the algorithm find the optimal greedy policy?



---------------------------
Question 5: Now implement the Q=Learning algorithm. First test the algorithm with decreasing exploration during learning (i.e. k_epsilon < 1). Next, test the algorithm using constant exploration during learning (i.e. k_epsilon = 1). How does k_epsilon influence the solution?



---------------------------
Question 6: Compare the computational efficiency and performance of the Monte Carlo and Q=Learning algorithms. What are the fundamental reasons why one algorithm performs better than the other?



---------------------------